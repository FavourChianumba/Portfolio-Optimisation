{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modern Portfolio Optimization Toolkit - Interactive Exploration\n",
    "\n",
    "This notebook provides an interactive exploration of the portfolio optimization process, walking through each step of the analysis pipeline. We'll examine asset data, calculate risk metrics, generate efficient frontiers, and analyze portfolio strategies.\n",
    "\n",
    "## Table of Contents\n",
    "1. [Setup and Data Collection](#setup)\n",
    "2. [Exploratory Data Analysis](#eda)\n",
    "3. [Risk Metrics Analysis](#risk)\n",
    "4. [Portfolio Optimization](#optimization)\n",
    "5. [Advanced Optimization Techniques](#advanced)\n",
    "6. [Monte Carlo Simulations](#monte-carlo)\n",
    "7. [Backtesting Strategies](#backtesting)\n",
    "8. [Final Analysis and Recommendations](#recommendations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='setup'></a>\n",
    "## 1. Setup and Data Collection\n",
    "\n",
    "First, let's set up our environment and import the necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import os\n",
    "import json\n",
    "from datetime import datetime, timedelta\n",
    "from scipy import stats\n",
    "import time\n",
    "import concurrent.futures\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('fivethirtyeight')\n",
    "sns.set_palette('colorblind')\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "\n",
    "# Add project root to Python path\n",
    "project_root = Path().resolve().parent\n",
    "sys.path.append(str(project_root))\n",
    "\n",
    "# Import project modules\n",
    "from config.settings import settings\n",
    "from utils.logger import setup_logger\n",
    "from src import data_collection, data_cleaning, risk_metrics, optimization, monte_carlo, backtesting\n",
    "from src import factor_optimization, black_litterman\n",
    "\n",
    "# Setup logger\n",
    "logger = setup_logger('notebook')\n",
    "\n",
    "# Display settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.precision', 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Data Collection\n",
    "\n",
    "Let's collect asset price data and macroeconomic indicators. We'll try multiple data sources with a fallback mechanism: Yahoo Finance, Alpha Vantage, Polygon, and FRED for macro data. If all APIs fail, we'll generate synthetic data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define assets and time period\n",
    "assets = [\n",
    "    \"SPY\",   # S&P 500\n",
    "    \"QQQ\",   # Nasdaq 100\n",
    "    \"TLT\",   # Long-Term Treasury\n",
    "    \"GLD\",   # Gold\n",
    "    \"AAPL\",  # Apple\n",
    "    \"MSFT\",  # Microsoft\n",
    "    \"AMZN\",  # Amazon\n",
    "    \"JPM\",   # JPMorgan Chase\n",
    "    \"XOM\"    # Exxon Mobil\n",
    "]\n",
    "\n",
    "print(f\"Assets for analysis: {', '.join(assets)}\")\n",
    "\n",
    "# Set up time period\n",
    "end_date = datetime.now() - timedelta(days=1)\n",
    "start_date = end_date - timedelta(days=365*5)  # 5 years\n",
    "\n",
    "# Display data sources available\n",
    "print(\"\\nAttempting to collect data from the following sources:\")\n",
    "print(\"1. Yahoo Finance (primary)\")\n",
    "print(\"2. Polygon.io (fallback 1)\")\n",
    "print(\"3. Alpha Vantage (fallback 2)\")\n",
    "print(\"4. FRED (for macroeconomic data)\")\n",
    "print(\"5. Synthetic data generation (final fallback)\")\n",
    "\n",
    "# Collect data\n",
    "start_time = time.time()\n",
    "try:\n",
    "    asset_data, fred_data, yahoo_macro = data_collection.collect_data()\n",
    "    elapsed = time.time() - start_time\n",
    "    print(f\"\\nData collection successful in {elapsed:.2f} seconds\")\n",
    "    print(f\"Retrieved {len(asset_data.columns)} assets and {len(fred_data.columns) if fred_data is not None else 0} macro factors\")\n",
    "    \n",
    "    # Check which data source was used\n",
    "    # (This requires adding a data source identifier to the collect_data return)\n",
    "    if hasattr(data_collection, 'data_source_used'):\n",
    "        print(f\"Data source used: {data_collection.data_source_used}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error collecting data: {e}\")\n",
    "    print(\"Generating sample data instead...\")\n",
    "    # Generate sample data\n",
    "    asset_data = data_collection.generate_sample_data(assets, start_date, end_date)\n",
    "    fred_factors = [\"CPIAUCSL\", \"UNRATE\", \"FEDFUNDS\", \"T10Y2Y\", \"BAMLH0A0HYM2\"]\n",
    "    fred_data = data_collection.generate_sample_macro_data(fred_factors, start_date, end_date)\n",
    "    yahoo_macro = None\n",
    "    \n",
    "# Preview the data\n",
    "print(\"\\nAsset price data preview:\")\n",
    "display(asset_data.head())\n",
    "\n",
    "print(\"\\nMacro data preview:\")\n",
    "display(fred_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Data Cleaning and Preparation\n",
    "\n",
    "Now, let's clean the data and calculate returns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean asset data\n",
    "cleaned_asset_data, returns, monthly_returns = data_cleaning.clean_asset_data(asset_data)\n",
    "\n",
    "# Clean macro data\n",
    "cleaned_macro, macro_changes = data_cleaning.clean_macro_data()\n",
    "\n",
    "print(f\"Cleaned {len(cleaned_asset_data.columns)} assets with {len(cleaned_asset_data)} data points\")\n",
    "print(f\"Processed {len(cleaned_macro.columns)} macro factors\")\n",
    "\n",
    "# Preview returns data\n",
    "print(\"\\nDaily returns preview:\")\n",
    "display(returns.head())\n",
    "\n",
    "# Summary statistics\n",
    "print(\"\\nReturns summary statistics:\")\n",
    "display(returns.describe())\n",
    "\n",
    "# Check for and report missing values\n",
    "missing_count = cleaned_asset_data.isna().sum()\n",
    "if missing_count.sum() > 0:\n",
    "    print(\"\\nMissing values by asset:\")\n",
    "    display(missing_count[missing_count > 0])\n",
    "else:\n",
    "    print(\"\\nNo missing values found in cleaned data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='eda'></a>\n",
    "## 2. Exploratory Data Analysis\n",
    "\n",
    "Let's examine the data to understand the historical performance, volatility, and correlations of our assets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate cumulative returns\n",
    "cumulative_returns = (1 + returns).cumprod()\n",
    "\n",
    "# Plot cumulative returns\n",
    "plt.figure(figsize=(14, 10))\n",
    "cumulative_returns.plot()\n",
    "plt.title('Cumulative Returns', fontsize=16)\n",
    "plt.ylabel('Growth of $1', fontsize=14)\n",
    "plt.xlabel('Date', fontsize=14)\n",
    "plt.legend(fontsize=12)\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Calculate correlation matrix\n",
    "correlation_matrix = returns.corr()\n",
    "\n",
    "# Plot correlation heatmap\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0, linewidths=0.5)\n",
    "plt.title('Asset Return Correlations', fontsize=16)\n",
    "plt.xticks(fontsize=12, rotation=45)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate annualized returns and volatility\n",
    "annual_returns = returns.mean() * 252\n",
    "annual_volatility = returns.std() * np.sqrt(252)\n",
    "\n",
    "# Create risk-return scatter plot\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.scatter(annual_volatility, annual_returns, s=100)\n",
    "\n",
    "# Add labels to each point\n",
    "for i, asset in enumerate(returns.columns):\n",
    "    plt.annotate(asset, \n",
    "                 (annual_volatility[i], annual_returns[i]),\n",
    "                 xytext=(5, 5),\n",
    "                 textcoords='offset points',\n",
    "                 fontsize=12)\n",
    "\n",
    "plt.xlabel('Annualized Volatility', fontsize=14)\n",
    "plt.ylabel('Annualized Return', fontsize=14)\n",
    "plt.title('Risk-Return Tradeoff', fontsize=16)\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Create a DataFrame for the summary statistics\n",
    "risk_return_summary = pd.DataFrame({\n",
    "    'Annual Return': annual_returns,\n",
    "    'Annual Volatility': annual_volatility,\n",
    "    'Sharpe Ratio': (annual_returns - settings.RISK_FREE_RATE) / annual_volatility\n",
    "})\n",
    "\n",
    "# Sort by Sharpe ratio\n",
    "risk_return_summary = risk_return_summary.sort_values('Sharpe Ratio', ascending=False)\n",
    "\n",
    "# Display the summary\n",
    "display(risk_return_summary.style.format('{:.2%}'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate rolling volatility (21-day window, approximately 1 month)\n",
    "rolling_vol = returns.rolling(window=21).std() * np.sqrt(252)\n",
    "\n",
    "# Plot rolling volatility\n",
    "plt.figure(figsize=(14, 10))\n",
    "rolling_vol.plot()\n",
    "plt.title('21-Day Rolling Volatility (Annualized)', fontsize=16)\n",
    "plt.ylabel('Volatility', fontsize=14)\n",
    "plt.xlabel('Date', fontsize=14)\n",
    "plt.legend(fontsize=12)\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Calculate drawdowns\n",
    "peak = cumulative_returns.cummax()\n",
    "drawdown = (cumulative_returns / peak) - 1\n",
    "\n",
    "# Plot drawdowns\n",
    "plt.figure(figsize=(14, 10))\n",
    "drawdown.plot()\n",
    "plt.title('Historical Drawdowns', fontsize=16)\n",
    "plt.ylabel('Drawdown', fontsize=14)\n",
    "plt.xlabel('Date', fontsize=14)\n",
    "plt.legend(fontsize=12)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Distribution of Returns\n",
    "\n",
    "Let's examine the distribution of returns for each asset to understand their statistical properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to plot return distributions\n",
    "def plot_return_distribution(asset):\n",
    "    plt.figure(figsize=(14, 6))\n",
    "    \n",
    "    # Left subplot: Histogram\n",
    "    plt.subplot(1, 2, 1)\n",
    "    returns[asset].hist(bins=50, density=True, alpha=0.6)\n",
    "    \n",
    "    # Add normal distribution curve\n",
    "    x = np.linspace(returns[asset].min(), returns[asset].max(), 100)\n",
    "    y = stats.norm.pdf(x, returns[asset].mean(), returns[asset].std())\n",
    "    plt.plot(x, y, 'r--', linewidth=2)\n",
    "    \n",
    "    plt.title(f'{asset} Return Distribution vs. Normal', fontsize=14)\n",
    "    plt.xlabel('Daily Return', fontsize=12)\n",
    "    plt.ylabel('Density', fontsize=12)\n",
    "    \n",
    "    # Right subplot: QQ plot\n",
    "    plt.subplot(1, 2, 2)\n",
    "    stats.probplot(returns[asset].dropna(), dist=\"norm\", plot=plt)\n",
    "    plt.title(f'{asset} Q-Q Plot', fontsize=14)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Calculate and display statistics\n",
    "    skew = returns[asset].skew()\n",
    "    kurt = returns[asset].kurtosis()\n",
    "    jb_stat, jb_pval = stats.jarque_bera(returns[asset].dropna())\n",
    "    \n",
    "    print(f\"Skewness: {skew:.4f}\")\n",
    "    print(f\"Excess Kurtosis: {kurt:.4f}\")\n",
    "    print(f\"Jarque-Bera statistic: {jb_stat:.4f}, p-value: {jb_pval:.6f}\")\n",
    "    print(f\"Normal at 5% significance: {'No' if jb_pval < 0.05 else 'Yes'}\")\n",
    "\n",
    "# Let user interactively select an asset\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "def on_asset_change(change):\n",
    "    if change['type'] == 'change' and change['name'] == 'value':\n",
    "        plot_return_distribution(change['new'])\n",
    "\n",
    "asset_dropdown = widgets.Dropdown(\n",
    "    options=returns.columns.tolist(),\n",
    "    value=returns.columns[0],\n",
    "    description='Asset:',\n",
    "    disabled=False,\n",
    ")\n",
    "\n",
    "asset_dropdown.observe(on_asset_change, names='value')\n",
    "display(asset_dropdown)\n",
    "plot_return_distribution(asset_dropdown.value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Macro Factor Analysis\n",
    "\n",
    "Let's examine the relationship between macroeconomic factors and asset returns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge asset returns with macro changes\n",
    "# First we need to align dates\n",
    "aligned_data = pd.merge(returns, macro_changes, left_index=True, right_index=True, how='inner')\n",
    "\n",
    "# Calculate correlation between asset returns and macro changes\n",
    "macro_correlations = pd.DataFrame()\n",
    "\n",
    "for asset in returns.columns:\n",
    "    correlations = {}\n",
    "    for factor in macro_changes.columns:\n",
    "        corr = aligned_data[asset].corr(aligned_data[factor])\n",
    "        correlations[factor] = corr\n",
    "    macro_correlations[asset] = pd.Series(correlations)\n",
    "\n",
    "# Plot heatmap of correlations\n",
    "plt.figure(figsize=(14, 10))\n",
    "sns.heatmap(macro_correlations, annot=True, cmap='coolwarm', center=0, linewidths=0.5)\n",
    "plt.title('Correlation between Asset Returns and Macro Factors', fontsize=16)\n",
    "plt.xticks(fontsize=12, rotation=45)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='risk'></a>\n",
    "## 3. Risk Metrics Analysis\n",
    "\n",
    "Let's calculate and analyze various risk metrics for each asset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize risk metrics calculator\n",
    "risk_calculator = risk_metrics.RiskMetrics(returns_data=returns, prices_data=cleaned_asset_data)\n",
    "\n",
    "# Calculate volatility metrics\n",
    "vol_metrics = risk_calculator.calculate_volatility_metrics()\n",
    "\n",
    "# Convert dictionary to DataFrame for better visualization\n",
    "vol_df = pd.DataFrame.from_dict(vol_metrics, orient='index')\n",
    "\n",
    "# Display volatility metrics\n",
    "display(vol_df.style.format('{:.4f}'))\n",
    "\n",
    "# Plot key volatility metrics\n",
    "plt.figure(figsize=(14, 8))\n",
    "key_metrics = ['annual_volatility', 'upside_volatility', 'downside_volatility']\n",
    "vol_df[key_metrics].plot(kind='bar')\n",
    "plt.title('Volatility Metrics by Asset', fontsize=16)\n",
    "plt.ylabel('Volatility', fontsize=14)\n",
    "plt.xlabel('Asset', fontsize=14)\n",
    "plt.legend(fontsize=12)\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True, axis='y')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate tail risk metrics\n",
    "tail_metrics = risk_calculator.calculate_tail_risk()\n",
    "\n",
    "# Convert dictionary to DataFrame\n",
    "tail_df = pd.DataFrame.from_dict(tail_metrics, orient='index')\n",
    "\n",
    "# Display tail risk metrics\n",
    "display(tail_df.style.format('{:.4f}'))\n",
    "\n",
    "# Plot VaR and CVaR\n",
    "plt.figure(figsize=(14, 8))\n",
    "risk_measures = ['var_95_daily', 'cvar_95_daily']\n",
    "tail_df[risk_measures].plot(kind='bar')\n",
    "plt.title('Value at Risk (95%) and Conditional VaR by Asset', fontsize=16)\n",
    "plt.ylabel('Daily Loss (%)', fontsize=14)\n",
    "plt.xlabel('Asset', fontsize=14)\n",
    "plt.legend(['VaR (95%)', 'CVaR (95%)'], fontsize=12)\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True, axis='y')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot skewness and kurtosis\n",
    "plt.figure(figsize=(14, 8))\n",
    "moments = ['skewness', 'excess_kurtosis']\n",
    "tail_df[moments].plot(kind='bar')\n",
    "plt.title('Skewness and Excess Kurtosis by Asset', fontsize=16)\n",
    "plt.ylabel('Value', fontsize=14)\n",
    "plt.xlabel('Asset', fontsize=14)\n",
    "plt.legend(fontsize=12)\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True, axis='y')\n",
    "plt.axhline(y=0, color='r', linestyle='--')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate drawdown metrics\n",
    "drawdown_metrics = risk_calculator.calculate_drawdowns()\n",
    "\n",
    "# Convert dictionary to DataFrame\n",
    "drawdown_df = pd.DataFrame.from_dict(drawdown_metrics, orient='index')\n",
    "\n",
    "# Display key drawdown metrics\n",
    "display_cols = ['maximum_drawdown', 'average_drawdown', 'worst_dd_duration_days', 'underwater_ratio']\n",
    "display(drawdown_df[display_cols].style.format({\n",
    "    'maximum_drawdown': '{:.2%}',\n",
    "    'average_drawdown': '{:.2%}',\n",
    "    'worst_dd_duration_days': '{:.0f}',\n",
    "    'underwater_ratio': '{:.2%}'\n",
    "}))\n",
    "\n",
    "# Plot maximum drawdowns\n",
    "plt.figure(figsize=(14, 8))\n",
    "drawdown_df['maximum_drawdown'].sort_values().plot(kind='barh')\n",
    "plt.title('Maximum Drawdown by Asset', fontsize=16)\n",
    "plt.xlabel('Maximum Drawdown', fontsize=14)\n",
    "plt.ylabel('Asset', fontsize=14)\n",
    "plt.grid(True, axis='x')\n",
    "plt.tight_layout()\n",
    "plt.gca().invert_yaxis()  # Invert y-axis for better visualization\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate performance metrics\n",
    "perf_metrics = risk_calculator.calculate_performance_metrics()\n",
    "\n",
    "# Convert dictionary to DataFrame\n",
    "perf_df = pd.DataFrame.from_dict(perf_metrics, orient='index')\n",
    "\n",
    "# Display performance metrics\n",
    "key_perf_cols = ['annualized_return', 'sharpe_ratio', 'sortino_ratio', 'calmar_ratio']\n",
    "display(perf_df[key_perf_cols].sort_values('sharpe_ratio', ascending=False).style.format({\n",
    "    'annualized_return': '{:.2%}',\n",
    "    'sharpe_ratio': '{:.2f}',\n",
    "    'sortino_ratio': '{:.2f}',\n",
    "    'calmar_ratio': '{:.2f}'\n",
    "}))\n",
    "\n",
    "# Plot performance metrics\n",
    "plt.figure(figsize=(14, 8))\n",
    "perf_df[key_perf_cols].sort_values('sharpe_ratio', ascending=False).plot(kind='bar')\n",
    "plt.title('Performance Metrics by Asset', fontsize=16)\n",
    "plt.ylabel('Value', fontsize=14)\n",
    "plt.xlabel('Asset', fontsize=14)\n",
    "plt.legend(fontsize=12)\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True, axis='y')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='optimization'></a>\n",
    "## 4. Portfolio Optimization\n",
    "\n",
    "Now, let's optimize our portfolio using various optimization techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize portfolio optimizer\n",
    "optimizer = optimization.PortfolioOptimizer(returns_data=returns)\n",
    "\n",
    "# Generate efficient frontier\n",
    "ef_results, min_vol_portfolio, max_sharpe_portfolio = optimizer.generate_efficient_frontier(num_portfolios=5000, save_results=False)\n",
    "\n",
    "# Plot efficient frontier\n",
    "plt.figure(figsize=(14, 10))\n",
    "plt.scatter(ef_results['Volatility'], ef_results['Return'], c=ef_results['Sharpe'], cmap='viridis', alpha=0.7)\n",
    "plt.colorbar(label='Sharpe Ratio')\n",
    "\n",
    "# Plot optimal portfolios\n",
    "plt.scatter(min_vol_portfolio['Volatility'], min_vol_portfolio['Return'], \n",
    "           marker='*', color='r', s=300, label='Minimum Volatility')\n",
    "plt.scatter(max_sharpe_portfolio['Volatility'], max_sharpe_portfolio['Return'], \n",
    "           marker='*', color='g', s=300, label='Maximum Sharpe')\n",
    "\n",
    "# Add individual assets\n",
    "for i, asset in enumerate(returns.columns):\n",
    "    asset_vol = vol_df.loc[asset, 'annual_volatility']\n",
    "    asset_ret = perf_df.loc[asset, 'annualized_return']\n",
    "    plt.scatter(asset_vol, asset_ret, marker='o', s=100)\n",
    "    plt.annotate(asset, (asset_vol, asset_ret), xytext=(5, 5), textcoords='offset points')\n",
    "\n",
    "plt.title('Efficient Frontier', fontsize=16)\n",
    "plt.xlabel('Annualized Volatility', fontsize=14)\n",
    "plt.ylabel('Annualized Return', fontsize=14)\n",
    "plt.legend(fontsize=12)\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Display optimal portfolio details\n",
    "print(\"Minimum Volatility Portfolio:\")\n",
    "print(f\"Return: {min_vol_portfolio['Return']:.4f}\")\n",
    "print(f\"Volatility: {min_vol_portfolio['Volatility']:.4f}\")\n",
    "print(f\"Sharpe Ratio: {min_vol_portfolio['Sharpe']:.4f}\")\n",
    "print(\"\\nWeights:\")\n",
    "for asset, weight in min_vol_portfolio['Weights'].items():\n",
    "    print(f\"{asset}: {weight:.2%}\")\n",
    "\n",
    "print(\"\\n\" + \"-\"*50 + \"\\n\")\n",
    "\n",
    "print(\"Maximum Sharpe Portfolio:\")\n",
    "print(f\"Return: {max_sharpe_portfolio['Return']:.4f}\")\n",
    "print(f\"Volatility: {max_sharpe_portfolio['Volatility']:.4f}\")\n",
    "print(f\"Sharpe Ratio: {max_sharpe_portfolio['Sharpe']:.4f}\")\n",
    "print(\"\\nWeights:\")\n",
    "for asset, weight in max_sharpe_portfolio['Weights'].items():\n",
    "    print(f\"{asset}: {weight:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate optimized portfolios using different techniques\n",
    "print(\"Optimizing portfolio for maximum Sharpe ratio...\")\n",
    "max_sharpe_optimized = optimizer.optimize_sharpe_ratio(save_results=False)\n",
    "\n",
    "print(\"\\nOptimizing portfolio for minimum volatility...\")\n",
    "min_vol_optimized = optimizer.optimize_minimum_volatility(save_results=False)\n",
    "\n",
    "print(\"\\nOptimizing portfolio using risk parity...\")\n",
    "risk_parity_portfolio = optimizer.optimize_risk_parity(save_results=False)\n",
    "\n",
    "# Generate efficient frontier curve\n",
    "ef_curve, ef_portfolios = optimizer.generate_efficient_frontier_curve(points=20, save_results=False)\n",
    "\n",
    "# Plot efficient frontier curve\n",
    "plt.figure(figsize=(14, 10))\n",
    "plt.plot(ef_curve['Volatility'], ef_curve['Return'], 'b-', linewidth=3, label='Efficient Frontier')\n",
    "\n",
    "# Plot optimized portfolios\n",
    "plt.scatter(min_vol_optimized['Volatility'], min_vol_optimized['Return'], \n",
    "           marker='*', color='r', s=300, label='Min Volatility')\n",
    "plt.scatter(max_sharpe_optimized['Volatility'], max_sharpe_optimized['Return'], \n",
    "           marker='*', color='g', s=300, label='Max Sharpe')\n",
    "plt.scatter(risk_parity_portfolio['Volatility'], risk_parity_portfolio['Return'], \n",
    "           marker='*', color='purple', s=300, label='Risk Parity')\n",
    "\n",
    "# Add individual assets\n",
    "for i, asset in enumerate(returns.columns):\n",
    "    asset_vol = vol_df.loc[asset, 'annual_volatility']\n",
    "    asset_ret = perf_df.loc[asset, 'annualized_return']\n",
    "    plt.scatter(asset_vol, asset_ret, marker='o', s=100)\n",
    "    plt.annotate(asset, (asset_vol, asset_ret), xytext=(5, 5), textcoords='offset points')\n",
    "\n",
    "# Add Capital Market Line\n",
    "risk_free_rate = settings.RISK_FREE_RATE\n",
    "max_sharpe_vol = max_sharpe_optimized['Volatility']\n",
    "max_sharpe_ret = max_sharpe_optimized['Return']\n",
    "slope = (max_sharpe_ret - risk_free_rate) / max_sharpe_vol\n",
    "x_cml = np.linspace(0, max(ef_curve['Volatility']) * 1.2, 100)\n",
    "y_cml = risk_free_rate + slope * x_cml\n",
    "plt.plot(x_cml, y_cml, 'r--', label='Capital Market Line')\n",
    "\n",
    "plt.title('Efficient Frontier and Optimized Portfolios', fontsize=16)\n",
    "plt.xlabel('Annualized Volatility', fontsize=14)\n",
    "plt.ylabel('Annualized Return', fontsize=14)\n",
    "plt.legend(fontsize=12)\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare portfolio weights across different optimization methods\n",
    "portfolio_weights = pd.DataFrame({\n",
    "    'Max Sharpe': pd.Series(max_sharpe_optimized['Weights']),\n",
    "    'Min Volatility': pd.Series(min_vol_optimized['Weights']),\n",
    "    'Risk Parity': pd.Series(risk_parity_portfolio['Weights']),\n",
    "    'Equal Weight': pd.Series({asset: 1/len(returns.columns) for asset in returns.columns})\n",
    "})\n",
    "\n",
    "# Display portfolio weights\n",
    "display(portfolio_weights.style.format('{:.2%}'))\n",
    "\n",
    "# Plot portfolio weights as stacked bar chart\n",
    "portfolio_weights.plot(kind='bar', stacked=True, figsize=(14, 8))\n",
    "plt.title('Asset Allocation Comparison', fontsize=16)\n",
    "plt.xlabel('Asset', fontsize=14)\n",
    "plt.ylabel('Weight', fontsize=14)\n",
    "plt.legend(title='Strategy', fontsize=12)\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True, axis='y')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze risk parity portfolio\n",
    "if 'Risk_Contributions' in risk_parity_portfolio:\n",
    "    risk_contrib = pd.Series(risk_parity_portfolio['Risk_Contributions'])\n",
    "    weights = pd.Series(risk_parity_portfolio['Weights'])\n",
    "    \n",
    "    # Compare weights vs risk contributions\n",
    "    comparison = pd.DataFrame({\n",
    "        'Weight': weights,\n",
    "        'Risk Contribution': risk_contrib\n",
    "    })\n",
    "    \n",
    "    # Display comparison\n",
    "    display(comparison.style.format('{:.2%}'))\n",
    "    \n",
    "    # Plot comparison\n",
    "    comparison.plot(kind='bar', figsize=(14, 8))\n",
    "    plt.title('Risk Parity: Weights vs Risk Contributions', fontsize=16)\n",
    "    plt.xlabel('Asset', fontsize=14)\n",
    "    plt.ylabel('Percentage', fontsize=14)\n",
    "    plt.legend(fontsize=12)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.grid(True, axis='y')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='advanced'></a>\n",
    "## 5. Advanced Optimization Techniques\n",
    "\n",
    "Now let's explore more sophisticated optimization techniques: Factor-Based Optimization and the Black-Litterman Model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Factor-Based Portfolio Optimization\n",
    "\n",
    "Factor-based optimization extends beyond classic Modern Portfolio Theory by incorporating common risk factors that drive asset returns. This approach provides better risk decomposition and improved diversification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize factor optimizer\n",
    "factor_opt = factor_optimization.FactorOptimizer(returns_data=returns)\n",
    "\n",
    "# Generate factors and estimate the factor model\n",
    "print(\"Estimating factor model...\")\n",
    "factor_exposures = factor_opt.factor_exposures\n",
    "\n",
    "# Display factor exposures (betas)\n",
    "print(\"\\nFactor exposures for each asset:\")\n",
    "display(factor_exposures.style.format('{:.4f}'))\n",
    "\n",
    "# Visualize factor exposures\n",
    "plt.figure(figsize=(14, 10))\n",
    "factor_exposures.drop('const', axis=1).plot(kind='bar')\n",
    "plt.title('Factor Exposures by Asset', fontsize=16)\n",
    "plt.xlabel('Asset', fontsize=14)\n",
    "plt.ylabel('Exposure (Beta)', fontsize=14)\n",
    "plt.legend(title='Factor', fontsize=12)\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True, axis='y')\n",
    "plt.axhline(y=0, color='r', linestyle='--')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimize factor-based portfolio\n",
    "print(\"Optimizing factor-based portfolio for maximum Sharpe ratio...\")\n",
    "factor_portfolio = factor_opt.optimize_factor_portfolio(objective='sharpe', save_results=False)\n",
    "\n",
    "# Display portfolio details\n",
    "print(\"\\nFactor-Based Portfolio (Max Sharpe):\")\n",
    "print(f\"Return: {factor_portfolio['return']:.4f}\")\n",
    "print(f\"Volatility: {factor_portfolio['volatility']:.4f}\")\n",
    "print(f\"Sharpe Ratio: {factor_portfolio['sharpe_ratio']:.4f}\")\n",
    "\n",
    "print(\"\\nWeights:\")\n",
    "sorted_weights = sorted(factor_portfolio['weights'].items(), key=lambda x: x[1], reverse=True)\n",
    "for asset, weight in sorted_weights:\n",
    "    print(f\"{asset}: {weight:.2%}\")\n",
    "\n",
    "print(\"\\nFactor Exposures:\")\n",
    "for factor, exposure in factor_portfolio['factor_exposures'].items():\n",
    "    if factor != 'const':  # Skip the constant term\n",
    "        print(f\"{factor}: {exposure:.4f}\")\n",
    "\n",
    "# Visualize factor portfolio weights\n",
    "plt.figure(figsize=(10, 10))\n",
    "weights_series = pd.Series(factor_portfolio['weights'])\n",
    "weights_series = weights_series[weights_series > 0.01]  # Filter for non-zero weights\n",
    "weights_series.plot.pie(autopct='%1.1f%%', startangle=90)\n",
    "plt.title('Factor-Based Portfolio Allocation', fontsize=16)\n",
    "plt.ylabel('')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Create factor-tilted portfolio (example with momentum tilt)\n",
    "print(\"\\nCreating a momentum-tilted portfolio...\")\n",
    "momentum_portfolio = factor_opt.optimize_factor_tilted_portfolio(\n",
    "    target_factor_exposures={'MOM': 0.2},  # Positive exposure to momentum\n",
    "    objective='max_return',\n",
    "    save_results=False\n",
    ")\n",
    "\n",
    "print(\"\\nMomentum-Tilted Portfolio:\")\n",
    "print(f\"Return: {momentum_portfolio['return']:.4f}\")\n",
    "print(f\"Volatility: {momentum_portfolio['volatility']:.4f}\")\n",
    "print(f\"Sharpe Ratio: {momentum_portfolio['sharpe_ratio']:.4f}\")\n",
    "\n",
    "print(\"\\nFactor Exposures:\")\n",
    "for factor, exposure in momentum_portfolio['factor_exposures'].items():\n",
    "    if factor != 'const':  # Skip the constant term\n",
    "        print(f\"{factor}: {exposure:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Black-Litterman Model\n",
    "\n",
    "The Black-Litterman model allows us to incorporate subjective views on expected returns while maintaining the advantages of mean-variance optimization. This resolves key issues with classic optimization, such as extreme weights and high sensitivity to input estimates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Black-Litterman optimizer\n",
    "bl_opt = black_litterman.BlackLittermanOptimizer(returns_data=returns)\n",
    "\n",
    "# Add investor views based on our analysis\n",
    "# Find assets with highest and lowest returns for demonstration\n",
    "top_performers = annual_returns.sort_values(ascending=False).head(2).index\n",
    "bottom_performers = annual_returns.sort_values().head(2).index\n",
    "\n",
    "print(\"Adding investor views:\")\n",
    "if len(top_performers) > 0:\n",
    "    # Absolute view on top performer\n",
    "    bl_opt.add_absolute_view(top_performers[0], 0.15, 0.7)  # 15% return with 70% confidence\n",
    "    print(f\"- Absolute view: {top_performers[0]} will have 15% return (70% confidence)\")\n",
    "\n",
    "if len(top_performers) > 1 and len(bottom_performers) > 0:\n",
    "    # Relative view between a top and bottom performer\n",
    "    bl_opt.add_relative_view(top_performers[1], bottom_performers[0], 0.05, 0.6)  # 5% outperformance with 60% confidence\n",
    "    print(f\"- Relative view: {top_performers[1]} will outperform {bottom_performers[0]} by 5% (60% confidence)\")\n",
    "\n",
    "# Compute posterior estimates\n",
    "bl_opt.compute_posterior()\n",
    "\n",
    "# Compare prior and posterior expected returns\n",
    "print(\"\\nPrior vs Posterior Expected Returns:\")\n",
    "comparison = bl_opt.compare_prior_posterior(save_results=False)\n",
    "display(comparison.sort_values('Posterior', ascending=False).head(5).style.format({\n",
    "    'Prior': '{:.4f}',\n",
    "    'Posterior': '{:.4f}',\n",
    "    'Difference': '{:.4f}',\n",
    "    'Pct_Change': '{:.2f}%'\n",
    "}))\n",
    "\n",
    "# Optimize portfolio using Black-Litterman estimates\n",
    "bl_portfolio = bl_opt.optimize_portfolio(objective='sharpe', save_results=False)\n",
    "\n",
    "print(\"\\nBlack-Litterman Portfolio (Max Sharpe):\")\n",
    "print(f\"Return: {bl_portfolio['return']:.4f}\")\n",
    "print(f\"Volatility: {bl_portfolio['volatility']:.4f}\")\n",
    "print(f\"Sharpe Ratio: {bl_portfolio['sharpe_ratio']:.4f}\")\n",
    "\n",
    "print(\"\\nWeights:\")\n",
    "sorted_weights = sorted(bl_portfolio['weights'].items(), key=lambda x: x[1], reverse=True)\n",
    "for asset, weight in sorted_weights:\n",
    "    print(f\"{asset}: {weight:.2%}\")\n",
    "\n",
    "# Visualize BL portfolio weights\n",
    "plt.figure(figsize=(10, 10))\n",
    "weights_series = pd.Series(bl_portfolio['weights'])\n",
    "weights_series = weights_series[weights_series > 0.01]  # Filter for non-zero weights\n",
    "weights_series.plot.pie(autopct='%1.1f%%', startangle=90)\n",
    "plt.title('Black-Litterman Portfolio Allocation', fontsize=16)\n",
    "plt.ylabel('')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='monte-carlo'></a>\n",
    "## 6. Monte Carlo Simulations\n",
    "\n",
    "Let's run Monte Carlo simulations to project future portfolio performance. We'll use parallel processing to improve performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Monte Carlo simulator with max Sharpe weights\n",
    "simulator = monte_carlo.MonteCarloSimulator(returns_data=returns, portfolio_weights=max_sharpe_optimized['Weights'])\n",
    "\n",
    "# Set number of simulations and time horizon\n",
    "num_simulations = 1000\n",
    "time_horizon = 252 * 5  # 5 years of trading days\n",
    "initial_investment = 100000\n",
    "\n",
    "# Determine number of processes for parallel execution\n",
    "num_processes = min(4, max(1, os.cpu_count() - 1))  # Leave one CPU core free\n",
    "print(f\"Running simulations using {num_processes} parallel processes\")\n",
    "\n",
    "# Run simulations with different methods\n",
    "print(\"\\nRunning parametric simulation...\")\n",
    "start_time = time.time()\n",
    "param_sim, param_stats = simulator.run_simulation(\n",
    "    return_method='parametric', \n",
    "    num_simulations=num_simulations, \n",
    "    time_horizon=time_horizon, \n",
    "    initial_investment=initial_investment,\n",
    "    num_processes=num_processes,\n",
    "    save_results=False\n",
    ")\n",
    "print(f\"Parametric simulation completed in {time.time() - start_time:.2f} seconds\")\n",
    "\n",
    "print(\"\\nRunning historical simulation...\")\n",
    "start_time = time.time()\n",
    "hist_sim, hist_stats = simulator.run_simulation(\n",
    "    return_method='historical', \n",
    "    num_simulations=num_simulations, \n",
    "    time_horizon=time_horizon, \n",
    "    initial_investment=initial_investment,\n",
    "    num_processes=num_processes,\n",
    "    save_results=False\n",
    ")\n",
    "print(f\"Historical simulation completed in {time.time() - start_time:.2f} seconds\")\n",
    "\n",
    "print(\"\\nRunning bootstrap simulation...\")\n",
    "start_time = time.time()\n",
    "bootstrap_sim, bootstrap_stats = simulator.run_simulation(\n",
    "    return_method='bootstrap', \n",
    "    num_simulations=num_simulations, \n",
    "    time_horizon=time_horizon, \n",
    "    initial_investment=initial_investment,\n",
    "    num_processes=num_processes,\n",
    "    save_results=False\n",
    ")\n",
    "print(f\"Bootstrap simulation completed in {time.time() - start_time:.2f} seconds\")\n",
    "\n",
    "# Display simulation statistics\n",
    "stats_df = pd.DataFrame({\n",
    "    'Parametric': pd.Series(param_stats),\n",
    "    'Historical': pd.Series(hist_stats),\n",
    "    'Bootstrap': pd.Series(bootstrap_stats)\n",
    "})\n",
    "\n",
    "# Display key statistics\n",
    "key_stats = ['mean', 'median', 'min', 'max', 'std', 'percentile_5', 'percentile_95']\n",
    "display(stats_df.loc[key_stats].style.format('${:,.2f}'))\n",
    "\n",
    "# Calculate probability of meeting return targets\n",
    "return_targets = [0, 0.5, 1.0, 1.5, 2.0]  # 0% to 200%\n",
    "prob_df = pd.DataFrame(index=return_targets, columns=stats_df.columns)\n",
    "\n",
    "for target in return_targets:\n",
    "    target_value = initial_investment * (1 + target)\n",
    "    for method in prob_df.columns:\n",
    "        key = f'prob_return_{target:.1f}'\n",
    "        if key in stats_df.index:\n",
    "            prob_df.loc[target, method] = stats_df.loc[key, method]\n",
    "\n",
    "# Display probability table\n",
    "prob_df.index = [f\"{target*100:.0f}%\" for target in return_targets]\n",
    "display(prob_df.style.format('{:.2%}'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot simulation paths for the parametric method\n",
    "plt.figure(figsize=(14, 10))\n",
    "\n",
    "# Plot sample paths (limit to 100 for clarity)\n",
    "sample_paths = np.random.choice(param_sim.shape[1], min(100, param_sim.shape[1]), replace=False)\n",
    "for i in sample_paths[:20]:  # Limit to 20 paths for visualization\n",
    "    plt.plot(param_sim[:, i], linewidth=0.5, alpha=0.6, color='gray')\n",
    "\n",
    "# Plot percentiles\n",
    "percentiles = [5, 25, 50, 75, 95]\n",
    "percentile_values = np.percentile(param_sim, percentiles, axis=1)\n",
    "styles = ['--', '-.', '-', '-.', '--']\n",
    "colors = ['red', 'orange', 'black', 'green', 'blue']\n",
    "\n",
    "for i, p in enumerate(percentiles):\n",
    "    plt.plot(percentile_values[i], linewidth=2, \n",
    "             label=f'{p}th Percentile', linestyle=styles[i], color=colors[i])\n",
    "\n",
    "plt.title('Monte Carlo Simulation - Parametric Method', fontsize=16)\n",
    "plt.xlabel('Trading Days', fontsize=14)\n",
    "plt.ylabel('Portfolio Value ($)', fontsize=14)\n",
    "plt.legend(fontsize=12)\n",
    "plt.grid(True)\n",
    "plt.axhline(y=initial_investment, color='red', linestyle='--', alpha=0.5, label='Initial Investment')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot histogram of final values\n",
    "plt.figure(figsize=(14, 8))\n",
    "\n",
    "# Create histogram for each method\n",
    "final_values = {\n",
    "    'Parametric': param_sim[-1, :],\n",
    "    'Historical': hist_sim[-1, :],\n",
    "    'Bootstrap': bootstrap_sim[-1, :]\n",
    "}\n",
    "\n",
    "for method, values in final_values.items():\n",
    "    plt.hist(values, bins=50, alpha=0.5, label=method)\n",
    "\n",
    "plt.axvline(initial_investment, color='r', linestyle='--', \n",
    "           label=f'Initial Investment (${initial_investment:,.0f})')\n",
    "\n",
    "target_value = initial_investment * 2  # Double the initial investment\n",
    "plt.axvline(target_value, color='g', linestyle='--', \n",
    "           label=f'Double Investment (${target_value:,.0f})')\n",
    "\n",
    "plt.title('Distribution of Final Portfolio Values by Simulation Method', fontsize=16)\n",
    "plt.xlabel('Portfolio Value ($)', fontsize=14)\n",
    "plt.ylabel('Frequency', fontsize=14)\n",
    "plt.legend(fontsize=12)\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run stress tests\n",
    "stress_results = simulator.run_stress_test(initial_investment=initial_investment, save_results=False)\n",
    "\n",
    "# Display stress test results\n",
    "stress_df = pd.DataFrame()\n",
    "for scenario, result in stress_results.items():\n",
    "    if 'status' not in result or result['status'] != 'failed':\n",
    "        stress_df[scenario] = pd.Series({\n",
    "            'Description': result.get('description', scenario),\n",
    "            'Initial Value': result.get('initial_value', 0),\n",
    "            'Final Value': result.get('final_value', 0),\n",
    "            'Total Return': result.get('total_return', 0),\n",
    "            'Max Drawdown': result.get('max_drawdown', 0),\n",
    "            'Duration (Days)': result.get('duration_days', 0)\n",
    "        })\n",
    "\n",
    "# Display stress test results\n",
    "display(stress_df.T.style.format({\n",
    "    'Initial Value': '${:,.2f}',\n",
    "    'Final Value': '${:,.2f}',\n",
    "    'Total Return': '{:.2%}',\n",
    "    'Max Drawdown': '{:.2%}',\n",
    "    'Duration (Days)': '{:.0f}'\n",
    "}))\n",
    "\n",
    "# Plot stress scenario outcomes\n",
    "plt.figure(figsize=(14, 10))\n",
    "# Make sure we're not trying to drop a non-existent 'Description' key\n",
    "stress_return_series = stress_df.loc['Total Return']\n",
    "if 'Description' in stress_return_series.index:\n",
    "    stress_return_series = stress_return_series.drop('Description')\n",
    "stress_return_series.astype(float).sort_values().plot(kind='barh')\n",
    "plt.title('Stress Test Scenarios - Total Return', fontsize=16)\n",
    "plt.xlabel('Total Return', fontsize=14)\n",
    "plt.ylabel('Scenario', fontsize=14)\n",
    "plt.grid(True, axis='x')\n",
    "plt.tight_layout()\n",
    "plt.gca().invert_yaxis()  # Invert y-axis for better visualization\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='backtesting'></a>\n",
    "## 7. Backtesting Strategies\n",
    "\n",
    "Let's backtest different portfolio strategies to compare their historical performance, including our new advanced strategies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize backtester\n",
    "backtester = backtesting.PortfolioBacktester(prices_data=cleaned_asset_data, returns_data=returns)\n",
    "\n",
    "# Define strategies for comparison\n",
    "strategies = [\n",
    "    {\n",
    "        'name': 'Equal Weight',\n",
    "        'weights': {asset: 1.0/len(returns.columns) for asset in returns.columns},\n",
    "        'rebalance_frequency': 'M'\n",
    "    },\n",
    "    {\n",
    "        'name': 'Max Sharpe',\n",
    "        'weights': max_sharpe_optimized['Weights'],\n",
    "        'rebalance_frequency': 'M'\n",
    "    },\n",
    "    {\n",
    "        'name': 'Min Volatility',\n",
    "        'weights': min_vol_optimized['Weights'],\n",
    "        'rebalance_frequency': 'M'\n",
    "    },\n",
    "    {\n",
    "        'name': 'Risk Parity',\n",
    "        'weights': risk_parity_portfolio['Weights'],\n",
    "        'rebalance_frequency': 'M'\n",
    "    },\n",
    "    {\n",
    "        'name': 'Factor Model',\n",
    "        'weights': factor_portfolio['weights'],\n",
    "        'rebalance_frequency': 'M'\n",
    "    },\n",
    "    {\n",
    "        'name': 'Black-Litterman',\n",
    "        'weights': bl_portfolio['weights'],\n",
    "        'rebalance_frequency': 'M'\n",
    "    },\n",
    "    {\n",
    "        'name': 'Buy and Hold',\n",
    "        'weights': {asset: 1.0/len(returns.columns) for asset in returns.columns},\n",
    "        'rebalance_frequency': None\n",
    "    }\n",
    "]\n",
    "\n",
    "# Run backtest comparison\n",
    "print(\"Running backtest comparison...\")\n",
    "backtest_results, portfolio_values, portfolio_returns = backtester.backtest_strategy_comparison(\n",
    "    strategies=strategies,\n",
    "    initial_investment=100000,\n",
    "    save_results=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create performance summary table\n",
    "perf_summary = pd.DataFrame()\n",
    "for strategy, result in backtest_results.items():\n",
    "    perf_summary[strategy] = pd.Series({\n",
    "        'Total Return': result['total_return'],\n",
    "        'Annualized Return': result['annualized_return'],\n",
    "        'Annualized Volatility': result['annualized_volatility'],\n",
    "        'Sharpe Ratio': result['sharpe_ratio'],\n",
    "        'Max Drawdown': result['max_drawdown'],\n",
    "        'Final Value': result['final_value']\n",
    "    })\n",
    "\n",
    "# Display performance summary\n",
    "display(perf_summary.style.format({\n",
    "    'Total Return': '{:.2%}',\n",
    "    'Annualized Return': '{:.2%}',\n",
    "    'Annualized Volatility': '{:.2%}',\n",
    "    'Sharpe Ratio': '{:.2f}',\n",
    "    'Max Drawdown': '{:.2%}',\n",
    "    'Final Value': '${:,.2f}'\n",
    "}))\n",
    "\n",
    "# Plot cumulative performance\n",
    "plt.figure(figsize=(14, 10))\n",
    "for strategy, values in portfolio_values.items():\n",
    "    plt.plot(values.index, values, label=strategy)\n",
    "\n",
    "plt.title('Portfolio Value Over Time', fontsize=16)\n",
    "plt.xlabel('Date', fontsize=14)\n",
    "plt.ylabel('Portfolio Value ($)', fontsize=14)\n",
    "plt.legend(fontsize=12)\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot growth of $1 (normalized performance)\n",
    "plt.figure(figsize=(14, 10))\n",
    "for strategy, values in portfolio_values.items():\n",
    "    normalized = values / values.iloc[0]\n",
    "    plt.plot(normalized.index, normalized, label=strategy)\n",
    "\n",
    "plt.title('Growth of $1 Investment', fontsize=16)\n",
    "plt.xlabel('Date', fontsize=14)\n",
    "plt.ylabel('Growth Multiple', fontsize=14)\n",
    "plt.legend(fontsize=12)\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate drawdowns for each strategy\n",
    "drawdowns = {}\n",
    "for strategy, values in portfolio_values.items():\n",
    "    peak = values.cummax()\n",
    "    drawdowns[strategy] = (values / peak) - 1\n",
    "\n",
    "# Plot drawdowns\n",
    "plt.figure(figsize=(14, 10))\n",
    "for strategy, dd in drawdowns.items():\n",
    "    plt.plot(dd.index, dd, label=strategy)\n",
    "\n",
    "plt.title('Portfolio Drawdowns', fontsize=16)\n",
    "plt.xlabel('Date', fontsize=14)\n",
    "plt.ylabel('Drawdown', fontsize=14)\n",
    "plt.legend(fontsize=12)\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculate and plot rolling metrics (e.g., rolling 252-day Sharpe ratio)\n",
    "rolling_window = 252  # 1 year\n",
    "rolling_sharpes = {}\n",
    "\n",
    "for strategy, returns in portfolio_returns.items():\n",
    "    rolling_return = returns.rolling(window=rolling_window).mean() * 252\n",
    "    rolling_vol = returns.rolling(window=rolling_window).std() * np.sqrt(252)\n",
    "    rolling_sharpes[strategy] = (rolling_return - settings.RISK_FREE_RATE) / rolling_vol\n",
    "\n",
    "# Plot rolling Sharpe ratios\n",
    "plt.figure(figsize=(14, 10))\n",
    "for strategy, sharpe in rolling_sharpes.items():\n",
    "    plt.plot(sharpe.index, sharpe, label=strategy)\n",
    "\n",
    "plt.title('Rolling 1-Year Sharpe Ratio', fontsize=16)\n",
    "plt.xlabel('Date', fontsize=14)\n",
    "plt.ylabel('Sharpe Ratio', fontsize=14)\n",
    "plt.legend(fontsize=12)\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Backtest with dynamic allocation based on momentum\n",
    "def momentum_allocation(historical_returns, current_date):\n",
    "    \"\"\"Simple momentum strategy - allocate to assets with highest 6-month return\"\"\"\n",
    "    if len(historical_returns) < 126:  # Need at least 6 months\n",
    "        return {asset: 1/len(historical_returns.columns) for asset in historical_returns.columns}\n",
    "    \n",
    "    # Calculate 6-month returns\n",
    "    returns_6m = historical_returns.iloc[-126:].mean() * 252\n",
    "    \n",
    "    # Rank assets by return\n",
    "    ranked_assets = returns_6m.sort_values(ascending=False)\n",
    "    \n",
    "    # Allocate to top 3 assets\n",
    "    top_assets = ranked_assets.index[:3]\n",
    "    momentum_weights = {asset: 1/3 if asset in top_assets else 0 for asset in historical_returns.columns}\n",
    "    \n",
    "    return momentum_weights\n",
    "\n",
    "# Run dynamic backtest\n",
    "dynamic_results, dynamic_values, dynamic_returns, dynamic_weights = backtester.backtest_dynamic_allocation(\n",
    "    allocation_function=momentum_allocation,\n",
    "    lookback_window=252,\n",
    "    rebalance_frequency='M',\n",
    "    initial_investment=100000,\n",
    "    save_results=False\n",
    ")\n",
    "\n",
    "# Add dynamic strategy to performance summary\n",
    "perf_summary['Momentum'] = pd.Series({\n",
    "    'Total Return': dynamic_results['total_return'],\n",
    "    'Annualized Return': dynamic_results['annualized_return'],\n",
    "    'Annualized Volatility': dynamic_results['annualized_volatility'],\n",
    "    'Sharpe Ratio': dynamic_results['sharpe_ratio'],\n",
    "    'Max Drawdown': dynamic_results['max_drawdown'],\n",
    "    'Final Value': dynamic_results['final_value']\n",
    "})\n",
    "\n",
    "# Display updated performance summary\n",
    "display(perf_summary.style.format({\n",
    "    'Total Return': '{:.2%}',\n",
    "    'Annualized Return': '{:.2%}',\n",
    "    'Annualized Volatility': '{:.2%}',\n",
    "    'Sharpe Ratio': '{:.2f}',\n",
    "    'Max Drawdown': '{:.2%}',\n",
    "    'Final Value': '${:,.2f}'\n",
    "}))\n",
    "\n",
    "# Add dynamic strategy to portfolio values\n",
    "all_values = portfolio_values.copy()\n",
    "all_values['Momentum'] = dynamic_values\n",
    "\n",
    "# Plot updated growth of $1 (normalized performance)\n",
    "plt.figure(figsize=(14, 10))\n",
    "for strategy, values in all_values.items():\n",
    "    normalized = values / values.iloc[0]\n",
    "    plt.plot(normalized.index, normalized, label=strategy)\n",
    "\n",
    "plt.title('Growth of $1 Investment (Including Momentum Strategy)', fontsize=16)\n",
    "plt.xlabel('Date', fontsize=14)\n",
    "plt.ylabel('Growth Multiple', fontsize=14)\n",
    "plt.legend(fontsize=12)\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run with macro factor overlays\n",
    "print(\"\\nRunning backtest with macroeconomic factor overlays...\")\n",
    "try:\n",
    "    macro_results, macro_values, macro_returns, macro_weights = backtester.backtest_with_macro_factors(\n",
    "        weights=max_sharpe_optimized['Weights'],\n",
    "        initial_investment=100000,\n",
    "        save_results=False\n",
    "    )\n",
    "    \n",
    "    # Add to performance summary\n",
    "    perf_summary['Macro Factors'] = pd.Series({\n",
    "        'Total Return': macro_results['total_return'],\n",
    "        'Annualized Return': macro_results['annualized_return'],\n",
    "        'Annualized Volatility': macro_results['annualized_volatility'],\n",
    "        'Sharpe Ratio': macro_results['sharpe_ratio'],\n",
    "        'Max Drawdown': macro_results['max_drawdown'],\n",
    "        'Final Value': macro_results['final_value']\n",
    "    })\n",
    "    \n",
    "    # Display updated performance summary\n",
    "    display(perf_summary.style.format({\n",
    "        'Total Return': '{:.2%}',\n",
    "        'Annualized Return': '{:.2%}',\n",
    "        'Annualized Volatility': '{:.2%}',\n",
    "        'Sharpe Ratio': '{:.2f}',\n",
    "        'Max Drawdown': '{:.2%}',\n",
    "        'Final Value': '${:,.2f}'\n",
    "    }))\n",
    "    \n",
    "    # Plot macro weights over time\n",
    "    plt.figure(figsize=(14, 10))\n",
    "    # Sample weights to reduce clutter\n",
    "    sample_dates = pd.date_range(start=macro_weights.index[0], end=macro_weights.index[-1], freq='3M')\n",
    "    sample_dates = [date for date in sample_dates if date in macro_weights.index]\n",
    "    macro_weights.loc[sample_dates].plot.area(stacked=True)\n",
    "    plt.title('Macro Factor Strategy - Asset Allocation Over Time', fontsize=16)\n",
    "    plt.xlabel('Date', fontsize=14)\n",
    "    plt.ylabel('Weight', fontsize=14)\n",
    "    plt.legend(title='Asset', fontsize=12)\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Macro factor backtest failed: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='recommendations'></a>\n",
    "## 8. Final Analysis and Recommendations\n",
    "\n",
    "Let's summarize our findings and provide portfolio recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the best performing strategy\n",
    "best_strategy = perf_summary.T['Sharpe Ratio'].idxmax()\n",
    "best_return = perf_summary.T['Annualized Return'].idxmax()\n",
    "lowest_vol = perf_summary.T['Annualized Volatility'].idxmin()\n",
    "lowest_drawdown = perf_summary.T['Max Drawdown'].idxmax()  # Max of negative numbers is least negative\n",
    "\n",
    "print(f\"Best Strategy by Sharpe Ratio: {best_strategy} (Sharpe: {perf_summary[best_strategy]['Sharpe Ratio']:.2f})\")\n",
    "print(f\"Best Strategy by Return: {best_return} (Return: {perf_summary[best_return]['Annualized Return']:.2%})\")\n",
    "print(f\"Best Strategy by Volatility: {lowest_vol} (Volatility: {perf_summary[lowest_vol]['Annualized Volatility']:.2%})\")\n",
    "print(f\"Best Strategy by Max Drawdown: {lowest_drawdown} (Drawdown: {perf_summary[lowest_drawdown]['Max Drawdown']:.2%})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.1 Portfolio Recommendations\n",
    "\n",
    "Based on our comprehensive analysis, we can provide the following recommendations for different investor profiles:\n",
    "\n",
    "#### Conservative Investor (Low Risk Tolerance)\n",
    "- **Recommended Strategy**: Minimum Volatility Portfolio\n",
    "- **Key Benefits**: \n",
    "  - Lowest volatility among all strategies\n",
    "  - Reduced drawdowns during market stress\n",
    "  - Stable, consistent returns\n",
    "- **Asset Allocation**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display Min Vol weights\n",
    "min_vol_weights = pd.Series(min_vol_optimized['Weights']).sort_values(ascending=False)\n",
    "display(min_vol_weights.to_frame('Weight').style.format('{:.2%}'))\n",
    "\n",
    "# Plot Min Vol weights as pie chart\n",
    "plt.figure(figsize=(10, 10))\n",
    "non_zero_weights = min_vol_weights[min_vol_weights > 0.01]\n",
    "other_weight = 1 - non_zero_weights.sum()\n",
    "if other_weight > 0:\n",
    "    non_zero_weights['Other'] = other_weight\n",
    "non_zero_weights.plot.pie(autopct='%1.1f%%', startangle=90)\n",
    "plt.title('Minimum Volatility Portfolio Allocation', fontsize=16)\n",
    "plt.ylabel('')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Balanced Investor (Moderate Risk Tolerance)\n",
    "- **Recommended Strategy**: Risk Parity Portfolio or Black-Litterman Portfolio\n",
    "- **Key Benefits**: \n",
    "  - Balanced risk contribution from each asset\n",
    "  - Better diversification than concentration-based strategies\n",
    "  - Good compromise between return and risk\n",
    "- **Asset Allocation**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display Black-Litterman weights or Risk Parity weights based on backtesting results\n",
    "if perf_summary['Black-Litterman']['Sharpe Ratio'] > perf_summary['Risk Parity']['Sharpe Ratio']:\n",
    "    weights = pd.Series(bl_portfolio['weights']).sort_values(ascending=False)\n",
    "    title = \"Black-Litterman Portfolio Allocation\"\n",
    "else:\n",
    "    weights = pd.Series(risk_parity_portfolio['Weights']).sort_values(ascending=False)\n",
    "    title = \"Risk Parity Portfolio Allocation\"\n",
    "\n",
    "display(weights.to_frame('Weight').style.format('{:.2%}'))\n",
    "\n",
    "# Plot weights as pie chart\n",
    "plt.figure(figsize=(10, 10))\n",
    "non_zero_weights = weights[weights > 0.01]\n",
    "other_weight = 1 - non_zero_weights.sum()\n",
    "if other_weight > 0:\n",
    "    non_zero_weights['Other'] = other_weight\n",
    "non_zero_weights.plot.pie(autopct='%1.1f%%', startangle=90)\n",
    "plt.title(title, fontsize=16)\n",
    "plt.ylabel('')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Growth Investor (High Risk Tolerance)\n",
    "- **Recommended Strategy**: Factor-Based Portfolio or Maximum Sharpe Portfolio\n",
    "- **Key Benefits**: \n",
    "  - Highest risk-adjusted returns\n",
    "  - Strong absolute performance\n",
    "  - Optimal balance of risk and return\n",
    "- **Asset Allocation**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display Factor-Based weights or Max Sharpe weights based on backtesting results\n",
    "if 'Factor Model' in perf_summary.columns and perf_summary['Factor Model']['Sharpe Ratio'] > perf_summary['Max Sharpe']['Sharpe Ratio']:\n",
    "    weights = pd.Series(factor_portfolio['weights']).sort_values(ascending=False)\n",
    "    title = \"Factor-Based Portfolio Allocation\"\n",
    "else:\n",
    "    weights = pd.Series(max_sharpe_optimized['Weights']).sort_values(ascending=False)\n",
    "    title = \"Maximum Sharpe Portfolio Allocation\"\n",
    "\n",
    "display(weights.to_frame('Weight').style.format('{:.2%}'))\n",
    "\n",
    "# Plot weights as pie chart\n",
    "plt.figure(figsize=(10, 10))\n",
    "non_zero_weights = weights[weights > 0.01]\n",
    "other_weight = 1 - non_zero_weights.sum()\n",
    "if other_weight > 0:\n",
    "    non_zero_weights['Other'] = other_weight\n",
    "non_zero_weights.plot.pie(autopct='%1.1f%%', startangle=90)\n",
    "plt.title(title, fontsize=16)\n",
    "plt.ylabel('')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aggressive Investor (Very High Risk Tolerance)\n",
    "- **Recommended Strategy**: Momentum-Based Portfolio\n",
    "- **Key Benefits**: \n",
    "  - Potential for higher returns\n",
    "  - Adaptability to market conditions\n",
    "  - Exploits market trends\n",
    "- **Considerations**: \n",
    "  - Higher turnover and potentially higher trading costs\n",
    "  - More active management required\n",
    "  - Higher volatility and potential drawdowns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2 Monte Carlo Projections\n",
    "\n",
    "Based on our Monte Carlo simulations, we can provide the following projections for a $100,000 investment in the best-performing portfolio over a 5-year horizon:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display key Monte Carlo statistics\n",
    "mc_summary = pd.DataFrame({\n",
    "    'Metric': ['Expected Final Value', 'Median Final Value', '5th Percentile (Downside)', '95th Percentile (Upside)'],\n",
    "    'Value': [\n",
    "        param_stats['mean'],\n",
    "        param_stats['median'],\n",
    "        param_stats['percentile_5'],\n",
    "        param_stats['percentile_95']\n",
    "    ]\n",
    "})\n",
    "\n",
    "display(mc_summary.set_index('Metric').style.format('${:,.2f}'))\n",
    "\n",
    "# Display probability of achieving different return targets\n",
    "targets = [0, 0.25, 0.5, 0.75, 1.0, 1.5, 2.0]\n",
    "prob_summary = pd.DataFrame({\n",
    "    'Return Target': [f\"{t*100:.0f}%\" for t in targets],\n",
    "    'Final Value': [initial_investment * (1 + t) for t in targets],\n",
    "    'Probability': [param_stats.get(f'prob_return_{t:.1f}', np.nan) for t in targets]\n",
    "})\n",
    "\n",
    "display(prob_summary.style.format({\n",
    "    'Final Value': '${:,.2f}',\n",
    "    'Probability': '{:.2%}'\n",
    "}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.3 Key Findings and Conclusions\n",
    "\n",
    "1. **Optimal Diversification**: Our analysis demonstrates the importance of proper diversification across asset classes. The optimized portfolios consistently outperformed individual assets on a risk-adjusted basis.\n",
    "\n",
    "2. **Strategy Performance**: Our backtests show that advanced strategies like Factor-Based, Black-Litterman, and Risk Parity offer improved performance over traditional methods in many scenarios.\n",
    "\n",
    "3. **Asset Selection**: Gold (GLD) and Treasury bonds (TLT) played important roles in portfolio optimization, particularly for risk reduction. Technology stocks (AAPL, MSFT) were key contributors to return enhancement.\n",
    "\n",
    "4. **Monte Carlo Projections**: The simulation results suggest that our optimized portfolio has a strong probability of significant growth over a 5-year horizon, with manageable downside risk.\n",
    "\n",
    "5. **Stress Testing**: The portfolio shows resilience in stress scenarios, with our optimized portfolios demonstrating strong risk-return characteristics even in adverse market conditions.\n",
    "\n",
    "6. **Advanced Techniques**: The Factor-Based and Black-Litterman approaches provide valuable enhancements:\n",
    "   - Factor model helps identify and control exposure to fundamental market risks\n",
    "   - Black-Litterman allows incorporation of views while maintaining reasonable allocations\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "1. **Regular Rebalancing**: Implement a systematic rebalancing approach based on the selected strategy.\n",
    "\n",
    "2. **Periodic Re-optimization**: Re-run the optimization quarterly to account for changing market dynamics.\n",
    "\n",
    "3. **Risk Monitoring**: Continuously monitor the risk metrics, particularly volatility and drawdowns.\n",
    "\n",
    "4. **Implementation Considerations**: Consider transaction costs, taxes, and liquidity when implementing the selected strategy.\n",
    "\n",
    "5. **Multi-Asset Extension**: Consider extending the analysis to include more asset classes like real estate, commodities, and alternative investments."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
